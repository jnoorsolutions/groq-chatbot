
# ğŸ¤– Groq Chatbot with Memory â€“ Streamlit App

This is a simple **chatbot application** built using:
- ğŸ§  [LangChain](https://python.langchain.com)
- âš¡ [Groq LLMs](https://groq.com/)
- ğŸŒ [Streamlit](https://streamlit.io)
- ğŸ§  Memory support using `ConversationBufferMemory`

---

## ğŸš€ Features

âœ… Chat with powerful Groq LLMs  
âœ… Persistent memory across conversation  
âœ… Streamlit UI with chat bubbles  
âœ… Sidebar options for model, temperature, and token limits  
âœ… Easily deployable on **Streamlit Cloud** or any VPS

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main_chat.py                       # Main Streamlit app
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml             # Secure API key storage (do not commit)
â””â”€â”€ README.md
```

---

## ğŸ§‘â€ğŸ’» How to Run Locally

### 1ï¸âƒ£ Clone the Repo

```bash
git clone https://github.com/yourusername/groq-chatbot.git
cd groq-chatbot
```

### 2ï¸âƒ£ Create Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
source venv/bin/activate  # on Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set API Key

Create `.streamlit/secrets.toml` file:

```toml
GROQ_API_KEY = "your-groq-api-key"
```

### 5ï¸âƒ£ Run the App

```bash
streamlit run app.py
```

App will run at: [http://localhost:8501](http://localhost:8501)

---

## ğŸŒ Deployment (Streamlit Cloud)

1. Push this repo to GitHub
2. Go to: [https://streamlit.io/cloud](https://streamlit.io/cloud)
3. Click â€œNew Appâ€ and link your GitHub repo
4. After deployment, add your secret:

**In Streamlit Cloud â†’ App Settings â†’ Secrets**
```
GROQ_API_KEY = your-real-groq-api-key
```

---

## ğŸ“Œ Sidebar Options

| Option       | Description                            |
|--------------|----------------------------------------|
| Model        | Choose between llama3, gemma2, etc.    |
| Temperature  | Controls creativity of response        |
| Max Tokens   | Max length of LLM output               |

---

## ğŸ“¦ Requirements

ğŸ“„ `requirements.txt`:
```txt
streamlit
python-dotenv
langchain
langchain-groq
```

---

## ğŸ›¡ï¸ Security Tip

**Never commit `.streamlit/secrets.toml` or API keys into GitHub!**

Add this to `.gitignore`:
```
.streamlit/secrets.toml
.env
```

---

## ğŸ‘¨â€ğŸ’» Credits

Developed by [JnoorSolutions]  
Powered by: Streamlit + Langchain + Groq

---

## ğŸ“„ License

This project is licensed under the MIT License.
